{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 1 Background Theory\n\nWhat is being modeled:\n\n- Created a Sphere'd Cube (chosen points on cube projected onto radius = 1 sphere), so that regions were more evently distributed. All corners of cube chosen as regions, thus there are 8 regions.\n\n- EEG channels located on the center of each face of the cube. Thus there are 6 EEG channels.\n\n- Added some randomness to initial values - to decorrelate the signals a bit. Looking for FC matrix to look similar to SC matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ## 1) Background / Theory\n#\n# 08:00-08:50 ~~ MORNING COFFEE & GREETS\n#\n# 08:50-09:00 - Intro to the workshop [Davide Momi](https://scholar.google.com/citations?user=I-BACCgAAAAJ&hl=en&oi=ao)/[John Griffiths](https://scholar.google.com/citations?user=xwkt6aQAAAAJ&hl=en&oi=ao)<br>\n# 09:00-09:45 - Intro to dynamics [Viktor Jirsa](https://scholar.google.com/citations?user=0ZVdLpMAAAAJ&hl=en) <br>\n# 09:45-10:30 - Intro to connectivity [Joana Cabral](https://scholar.google.com/citations?user=v3ZEOeMAAAAJ&hl=en&oi=ao) <br>\n# 10:30-11:15 - Intro to connectome-based neural mass modeling [Sorenza Bastiaens](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Sorenza+Bastiaens&btnG=) <br>\n# 11:15-12:15 - Hands-on Session 1 [Davide Momi](https://scholar.google.com/citations?user=I-BACCgAAAAJ&hl=en&oi=ao)/[John Griffiths](https://scholar.google.com/citations?user=xwkt6aQAAAAJ&hl=en&oi=ao)<br>\n#\n# 12:15-13:00 ~~ LUNCH\n\n# In[27]:\n\n\nget_ipython().system('pip install mne')\nget_ipython().system('pip install nilearn')\nget_ipython().system('pip install nibabel')\nget_ipython().system('pip install tvb-library')\nget_ipython().system('pip install gdown')\nget_ipython().system('pip install matplotlib')\nget_ipython().system('pip install Pillow')\nget_ipython().system('pip install seaborn')\nget_ipython().system('pip install pandoc')\n\n\n# In[13]:\n\n\nimport gdown\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfile_id = \"1xJfB8r0tbpnN5nHYund0hIRO2StZDUby?usp=sharing\"\noutput = \"./data\"\n\ngdown.download_folder(\n    id=file_id,\n    output=output)\n\n\n# In[25]:\n\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n# Path to the image file on Google Drive\nimage_path = './data/Speakers_1.png'\n\nimage_array = plt.imread(image_path)\n\n\n# Plot the image using Matplotlib\nplt.figure(figsize=(10, 10))  # Adjust the size as needed\n\nplt.imshow(image_array)\nplt.axis('off')  # Optional: Remove axes\nplt.show()\n\n\n# -----\n#\n# ## Contents\n#\n\n# [Overview](#overview)\n# [Setup](#setup)\n# [Neural mass model of local neural dynamics](#neural-mass-model-of-local-neural-dynamics)\n# [Network model of whole-brain anatomical connectivity](#network-model-of-whole-brain-anatomical-connectivity)\n# [Conclusions](#conclusions)\n# [References](#references)\n\n# ### Overview\n\n# This is the Hands-on Session #1 of the OHBM's Educational Course entitled \"Whole-brain, Connectome-based Models of Brain Dynamics: From Principles to Applications\"\n#\n# In this tutorial we will cover some of the key components involved in computational modelling of mesoscopic, whole-brain network dynamics.\n#\n# The paradigm we use for mathematically and computationally describing brain organization is called <b>connectome-based neural mass modelling</b>.\n# Within this framework, the two main components of setting up a whole brain model are\n#\n# 1) **node-level dynamics** and\n# 2) the large-scale **network topology**.\n#\n# We will examine each of these in term, for an exemplary neural mass model and brain network connectivity.\n#\n# This focus is on **resting** or 'steady-state' (as opposed to task- or stimulus-evoked) neural activity, at the relatively **fast timescales** measured by EEG, MEG, ECoG, LFP, etc. (as opposed to slower timescale signals seen in functional MRI).\n#\n# Demonstrations are done using a combination of pure-python code and simulations run using the [**The Virtual Brain Toolbox**](https://thevirtualbrain.org/tvb/zwei) who has the purpose of offering modern tools to the Neurosciences community, for computing, simulating and analyzing functional and structural data of human brains, brains modeled at the level of population of neurons.\n#\n\n# ### Setup\n\n# If you are running this notebook in Google Colab, you will need to install some packages. If you are running in a more standard python environment, you need to ensure that these packages are installed externally (typically with `pip install <package>` on the command line).\n\n# In[28]:\n\n\nfrom scipy.signal import welch\n\nimport nilearn as nl\nimport nibabel as nib\nfrom scipy.spatial.distance import cdist\nimport glob\nimport mne\nimport os.path as op\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom scipy import signal\nfrom scipy.signal import welch\nfrom scipy.optimize import fsolve\nfrom scipy.io import loadmat\n# Suppress warnings; keeps things cleaner\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Standard scientific python import commands\nimport os,sys,glob,numpy as np,pandas as pd,seaborn as sns\nsns.set_style('white')\n\nget_ipython().run_line_magic('matplotlib', 'inline')\nfrom matplotlib import pyplot as plt\nimport pickle\n\n# TVB stuff\nfrom tvb.simulator.lab import (models,connectivity,coupling,integrators,noise,simulator,\n                              surfaces,region_mapping,monitors,equations,patterns,plot_pattern)\n\nfrom nilearn.image import load_img\nfrom nilearn import plotting as nplot\nfrom nilearn import datasets\n\n\nimport math\nfrom tvb.simulator import models\nfrom ipywidgets import interactive\nfrom ipywidgets import interact, FloatSlider, interactive_output, HBox, VBox\n\n\n# ### Neural mass model of local neural dynamics\n\n# [*Jansen-Rit (1995)*](https://link.springer.com/article/10.1007/BF00199471) is a neural mass model that represents the macroscopic electrophysiological activity within a cortical column. This circuit consists of three interconnected neural populations: one for the pyramidal projection neuron and two for excitatory and inhibitory interneurons, forming two feedback loops.\n#\n# In the model, each neural population is described with two operators: a rate-to-potential operator describing the dynamics between synapses and dendritic trees, and a potential-to-rate operator representing the output firing rate produced at the soma. The model is thus structured in two steps to describe the populations and capture the dynamics of the circuit.\n#\n# The first step of the model involves transforming the average pulse density of action potentials received by the population into the average post-synaptic membrane potential. This step is known as the post-synaptic potential block and involves a linear transformation using an impulse response. The impulse response describes the dynamics between the synapses and dendritic trees:\n#\n\n#  \\begin{equation}\n#    h(t)=\\alpha \\beta te^{-\\beta t}    \\qquad \\text{for t} > 0,\n#  \\end{equation}\n\n# The variable $\\alpha$ is defined as the maximum amplitude of the postsynaptic potential and $\\beta$ represent a sum of the reciprocal of the time constant of the passive membrane and all other spatially distributed delays present in the dendritic network, condensed into a single lumped term. For the excitatory  populations $\\alpha$, $\\beta$ correspond to $A, a$ respectively, and for the inhibitory population $\\alpha$, $\\beta$ are $B, b$.\n#\n#  By convolving the incoming pulse with the impulse response, we can determine the relationship between the pulse rate and the corresponding membrane potential, and express it in the form of a second-order differential equation.\n#\n# The second step transforms the average membrane potential of the population into the average rate of action potentials fired by the neurons using a non-linear operator, and in this case, a sigmoid:\n\n#  \\begin{equation}\n#      S(v)=\\frac{2e_0}{1+e^{r(V_0-v)}}\n#  \\end{equation}\n\n# with $e_{0}$ representing the maximum firing rate, $r$ denoting the variance of firing thresholds, and $V_{0}$ corresponding to the mean firing threshold.\n#\n#\n# It is the combination of those two steps that allows the representation of the coarse grained activity of each population in the model. This results in a model with a set of non-linear second-order differential equations that can be re-expressed as sets of first order non-linear ODEs:\n\n# \\begin{eqnarray}\n#     \\dot{y}_{0}(t) &=& y_{3}(t)\\\\\n#     \\dot{y}_{3}(t) &=& AaS[y_{1}(t)-y_{2}(t)] - 2ay_{3}(t) - a^{2}y_{0}(t)\\\\\n#     \\dot{y}_{1}(t) &=& y_{4}(t)\\\\\n#     \\dot{y}_{4}(t) &=& Aa(p(t) + C_{2}S[C_{1}y_{0}(t)]) - 2ay_{4}(t) - a^{2}y_{1}(t)\\\\\n#     \\dot{y}_{2}(t) &=& y_{5}(t)\\\\\n#     \\dot{y}_{5}(t) &=& BbC_{4}S[C_{3}y_{0}] - 2by_{5}(t) - b^{2}y_{2}(t)\n# \\end{eqnarray}\n#\n\n# with $p(t)$ representing the external input to the system, and $C_i$ to the connectivity parameters (See below for graphical representation).\n#\n# In summary, the Jansen-Rit model captures the dynamics of a local cortico-cortical circuit through a two-step process. It transforms the incoming pulse density into post-synaptic potentials using an impulse response, and then converts the impulse response into a set of differential equations to describe the neural activity of each population. This model provides insights into the complex interactions within the cortical circuitry and aids in understanding the neural dynamics observed in the brain. The output of the pyramidal postsynaptic potentials (y1-y2) is considered as the equivalent of an EEG signal.\n\n# In[33]:\n\n\nfrom PIL import Image\nget_ipython().run_line_magic('matplotlib', 'inline')\n# Path to the image file on Google Drive\nimage_path = './data/JR_Model.png'\n\nimage_array = plt.imread(image_path)\n\n\n# Plot the image using Matplotlib\nplt.figure(figsize=(20, 20))  # Adjust the size as needed\n\nplt.imshow(image_array)\nplt.axis('off')  # Optional: Remove axes\nplt.show()\n\n\n\n# First we are gonna see the JR implementation in numpy\n\n# \\begin{equation}\n# Sigm(\\nu) = \\frac{2 \\nu_{max}}{1 + \\exp^{r(\\nu_{0} - \\nu)}}\n# \\end{equation}\n\n# In[34]:\n\n\n# JR Sigmoid function\ndef sigm(nu_max,v0,r,v):\n  action_potential = (2*nu_max)/(1+math.exp(r*(v0-v)))\n  return action_potential\n\ndef imp_Jansen(t,a,b):\n  Exc = A*a*t*math.exp(-a*t)\n  Inh = B*b*t*math.exp(-b*t)\n  return Exc, Inh\ndef exc_imp_Jansen(t,a,A):\n  Exc = A*a*t*math.exp(-a*t)\n  return Exc\n\n\n# In[35]:\n\n\ndef plot_sigmoid(nu_max, v0, r):\n    v_values = np.linspace(-10, 10, 100)\n    action_potentials = [sigm(nu_max, v0, r, v) for v in v_values]\n\n    plt.plot(v_values, action_potentials)\n    plt.xlabel('v')\n    plt.ylabel('Action Potential')\n    plt.title('Sigmoid Function')\n    plt.grid(True)\n    plt.show()\n\n# Define the interactive plot\ninteractive_plot = interactive(plot_sigmoid, nu_max=(0.1, 10.0), v0=(-10.0, 10.0), r=(0.1, 10.0))\n\n# Display the interactive plot\noutput = interactive_plot.children[-1]\noutput.layout.height = '350px'\ninteractive_plot\n\n\n# In[36]:\n\n\ndef plot_exc_impulse_response(A, a):\n    t_values = np.arange(0, 0.2, 0.001)\n    Exc = [exc_imp_Jansen(t, a, A) for t in t_values]\n\n    plt.plot(t_values, Exc)\n    plt.xlabel('t')\n    plt.ylabel('Excitatory Potential')\n    plt.title('Impulse Response')\n    plt.grid(True)\n    plt.show()\n\n# Define the interactive plot\ninteractive_plot = interactive(plot_exc_impulse_response, A = (0, 10.0), a=(50, 150))\n\n# Display the interactive plot\noutput = interactive_plot.children[-1]\noutput.layout.height = '350px'\ninteractive_plot\n\n\n# ### Available parameters are:\n#\n# $A$ = Maximum amplitude of EPSP [mV]. Also called average synaptic gain.\n#\n# $B$ = Maximum amplitude of IPSP [mV]. Also called average synaptic gain.\n#\n# $a$ = Reciprocal of the time constant of passive membrane and all other spatially distributed delays in the dendritic network [ms^-1]. Also called average synaptic time constant.\n#\n# $b$ = Reciprocal of the time constant of passive membrane and all\n# other spatially distributed delays in the dendritic network [ms^-1].\n# Also called average synaptic time constant.\n#\n# $v_0$ = Firing threshold (PSP) for which a 50% firing rate is achieved.In other words, it is the value of the average membrane potential corresponding to the inflection point of the sigmoid [mV]. The usual value for this parameter is 6.0.\n#\n# $\\nu_{max}$ = Determines the maximum firing rate of the neural population [s^-1].\n#\n# $r$ = Steepness of the sigmoidal transformation [mV^-1].\n#\n# $J$ = Average number of synapses between populations.\n#\n# $a_1$ = Average probability of synaptic contacts in the feedback excitatory loop.\n#\n# $a_2$ = Average probability of synaptic contacts in the slow feedback excitatory loop.\n#\n# $a_3$ = Average probability of synaptic contacts in the feedback inhibitory loop.\n#\n# $a_4$ = Average probability of synaptic contacts in the slow feedback inhibitory loop.\n#\n# $p_{min}$ = Minimum input firing rate.\n#\n# $p_{max}$ = Maximum input firing rate.\n#\n# $\\mu$ = Mean input firing rate\n\n# In[37]:\n\n\n# Parameter settings\nA = 3.25\nB = 22\nC = 135\nC1 = 1*C\nC2 = 0.8*C\nC3 = 0.25*C\nC4 = 0.25*C\nv0 = 6         # mV\ntau_e = 10\ntau_i = 20\na = (1/tau_e)*1000 # 100        # s^-1\nb = (1/tau_i)*1000 # 50         # s^-1\nnu_max = 2.5   # s^-1\nr = 0.56       # mV^-1\n\n# Simulation setting\nstart = 0.0\nstim_time =10\ndt = 1e-4\ntime_array = np.arange(start=start, stop=stim_time, step=dt)\nvec_len = len(time_array)\n\n# Input\nnoise = np.random.uniform(120,320,vec_len)\n# Output Initialization\ny = np.zeros((6,vec_len))\n\n\n# The equations of the Jansen-Rit model are the following:\n# \\begin{equation}\n# \\dot{y_{0}} = y_{3} \\\\\n# \\dot{y_{3}} = Aa Sigm(y_{1} -  y_{2}) - 2a y_{3} - a^{2} y_{0} \\\\\n# \\dot{y_{1}} = y_{4} \\\\\n# \\dot{y_{4}} = Aa [p(t) + \\alpha_2 J Sigm[\\alpha_1 J y_0] + lrc + src] -2a y_{4} - a^{2} y_{1}\\\\\n# \\dot{y_{2}} = y_{5} \\\\\n# \\dot{y_5} = Bb (\\alpha_4 J Sigm[\\alpha_3 J y_{0}]) - 2b y_{5} - b^{2} y_{2} \\\\\n# \\end{equation}\n#\n\n# In[38]:\n\n\n# Euler integration method to solve JR differential equations\nfor i in range (1,vec_len):\n  y[0,i] = y[0,i-1] + y[3,i-1]*dt\n  y[1,i] = y[1,i-1] + y[4,i-1]*dt\n  y[2,i] = y[2,i-1] + y[5,i-1]*dt\n  y[3,i] = y[3,i-1] + dt * (A*a*(sigm(nu_max,v0,r,(y[1,i-1]-y[2,i-1]))) - (2*a*y[3,i-1]) - (a**(2)*y[0,i-1]))\n  y[4,i] = y[4,i-1] + dt * (A*a*(noise[i-1] + (C2*sigm(nu_max,v0,r,(C1*y[0,i-1])))) - (2*a*y[4,i-1]) - (a**(2)*y[1,i-1]))\n  y[5,i] = y[5,i-1] + dt * (B*b*(C4*sigm(nu_max,v0,r,(C3*y[0,i-1]))) - (2*b*y[5,i-1]) - (b**(2)*y[2,i-1]))\n\noutput = y[1,:]-y[2,:]\nX = signal.resample(output, 10000)\nfreqs_Jansen,ps_vPN_Jansen = welch(X,fs=100, noverlap = 125, nperseg=1000)\n\n\n# In[39]:\n\n\n# Figures\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\nax2.set_xscale(\"log\")\nax2.set_yscale(\"log\")\nax1.plot(time_array[20000:40000],output[20000:40000], color='black')\nax1.set_xlabel('Time (s)')\nax2.set_xlabel('Frequency (Hz)')\nax1.set_ylabel('Output ($y_{1}-y_{2}$)')\nax2.set_ylabel('Power (A.U.)')\nax2.plot(freqs_Jansen,ps_vPN_Jansen, color='black')\n\n\n# This can also be performed by tvb...\n\n# In[40]:\n\n\n# Run JR single node in TVB\n\nn_step = 50000\ndt = 0.1\n\n# Define initial conditions\ninitconds = np.array([-4.,-4.,-4.,-4.,-4.,-4.])[:,np.newaxis]\n\n# fixed params for these examples : oscillatory\na= np.array([0.1])#[0.029])\nmu = np.array([0.22])#0.1085])\nb = np.array([0.05])\n# Initialize model instance with fixed params\nmod = models.JansenRit(v0=np.array([6.]), mu=mu, p_max=mu, p_min=mu,\n                       b = b, a =a)\n\n# Execute single-node simulation run\ntime,dat = mod.stationary_trajectory(n_step=n_step,dt=dt)\ny_0 = np.squeeze(dat[:,0,:,:])\ny_1 = np.squeeze(dat[:,1,:,:])\ny_2 = np.squeeze(dat[:,2,:,:])\n\n\nfreqs_Jansen_tvb,ps_vPN_Jansen_tvb = welch((y_1-y_2)[1000:],fs=1000, noverlap = 125, nperseg=1000)\n\n\n# In[41]:\n\n\n# Figures\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\nax2.set_xscale(\"log\")\nax2.set_yscale(\"log\")\nax1.plot(time[1000:2000],(y_1-y_2)[1000:2000], color='black')\nax1.set_xlabel('Time (s)')\nax2.set_xlabel('Frequency (Hz)')\nax1.set_ylabel('Output ($y_{1}-y_{2}$)')\nax2.set_ylabel('Power (A.U.)')\nax2.plot(freqs_Jansen_tvb,ps_vPN_Jansen_tvb, color='black')\n\n\n# In[42]:\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import welch\nfrom ipywidgets import interactive, FloatSlider\n\n# Define the parameter range for bifurcation diagram\nmu_range = np.linspace(0.2, 0.8, 100)\n\ndef simulate_and_plot(mu):\n    # Run JR single node in TVB\n    n_step = 50000\n    dt = 0.1\n\n    # Define initial conditions\n    initconds = np.array([-4., -4., -4., -4., -4., -4.])[:, np.newaxis]\n\n    # fixed params for these examples: oscillatory\n    a = np.array([0.1])\n    b = np.array([0.05])\n\n    # Initialize model instance with variable mu\n    mod = models.JansenRit(v0=np.array([6.]), mu=np.array([mu]), p_max=np.array([mu]),\n                           p_min=np.array([mu]), b=b, a=a)\n\n    # Execute single-node simulation run\n    time, dat = mod.stationary_trajectory(n_step=n_step, dt=dt)\n    y_0 = np.squeeze(dat[:, 0, :, :])\n    y_1 = np.squeeze(dat[:, 1, :, :])\n    y_2 = np.squeeze(dat[:, 2, :, :])\n\n    freqs_Jansen_tvb, ps_vPN_Jansen_tvb = welch((y_1 - y_2)[1000:], fs=1000, noverlap=125, nperseg=1000)\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    ax2.set_xscale(\"log\")\n    ax2.set_yscale(\"log\")\n    ax1.plot(time[1000:2000], (y_1 - y_2)[1000:2000], color='black')\n    ax1.set_xlabel('Time (s)')\n    ax2.set_xlabel('Frequency (Hz)')\n    ax1.set_ylabel('Output ($y_{1}-y_{2}$)')\n    ax2.set_ylabel('Power (A.U.)')\n    ax2.plot(freqs_Jansen_tvb, ps_vPN_Jansen_tvb, color='black')\n\n# Create an interactive slider for the parameter mu\nmu_slider = FloatSlider(min=0.2, max=100, step=0.01, value=0.5, description='mu')\n\n# Define the interactive function\ninteractive_plot = interactive(simulate_and_plot, mu=mu_slider)\n\n# Display the interactive plot\ninteractive_plot\n\n\n# In[43]:\n\n\ndf_JR = pd.DataFrame([y_0[1000:2000],y_1[1000:2000], y_2[1000:2000]],\n                     index=['y_0', 'y_1', 'y_2'],\n                     columns=time[1000:2000]).T\n\n\n# In[ ]:\n\n\n\n\n\n# ### Stability function\n\n# In[57]:\n\n\ndef differentiate_sigmoid(x, vmax, v0,  r):\n  ds_dx = (r*2*vmax*(np.exp(r*(v0-x)))) / (1+np.exp(r*(v0-x)))**2\n  return ds_dx\n\n\n# In[58]:\n\n\ndef stability_func(A,a):\n  A = A\n  B = 22\n  C = 135\n  c1 = 1*C\n  c2 = 0.8*C  #0.8\n  c3 = 0.25*C\n  c4 = 0.25*C\n  v0 = 6         # mV\n  a = a        # s^-1\n  b = 50         # s^-1\n  nu_max = 2.5   # s^-1\n  r = 0.56       # mV^-1\n  divA = (A/a)\n  divB = (B/b)\n  p_all = np.arange(-20,400,1)\n  #C3_all = np.arange(0.1,0.6,0.001)\n  #c3 = C3_all*C\n  #C4_all = np.arange(0.1,0.6,0.001)\n  #c4 = C4_all*C\n  y = np.random.rand(len(p_all))\n\n  final_res = []\n  for p in p_all:\n    x = np.arange(-4,100,0.0001)\n    y1 = x\n    y2 = (divA*p) + (divA*c2*sigm(nu_max,v0,r,divA*c1*sigm(nu_max,v0,r,x))) - (divB*c4*sigm(nu_max,v0,r,divA*c3*sigm(nu_max,v0,r,x)))\n    idx = np.argwhere(np.diff(np.sign(y1 - y2))).flatten()\n    final_res.append(idx)\n\n  new_values = []\n  for i in range(0,len(final_res)):\n    new_values.append(y1[final_res[i]])\n\n  un = 0\n  stability = []\n  for j in range(0,len(new_values)):\n      for me in range(0,len(new_values[j])):\n        J = np.zeros((6, 6))\n        fix_point = new_values[j][me]\n        first_coordinate = (A/a)*sigm(nu_max,v0,r,fix_point)\n        J[0, 3] = 1\n        J[1, 4] = 1\n        J[2, 5] = 1\n        J[3, 0] = -a**2\n        J[3,1] = A*a*differentiate_sigmoid(fix_point,vmax,v0,r)\n        J[3,2] = -A*a*differentiate_sigmoid(fix_point,vmax,v0,r)\n        J[3,3] = -2*a\n        J[4, 0] = (A*a*c2*c1)*differentiate_sigmoid(c1*first_coordinate,vmax,v0,r)\n        J[4, 1] = -a**2\n        #J[4, 3] = -2*a\n        J[4, 4] = -2*a\n        J[5, 0] = (b*B*c4*c3)*differentiate_sigmoid(c3*first_coordinate,vmax,v0,r)\n        J[5, 2] = -b**2\n        J[5, 5] = -2*b\n        evals = np.linalg.eigvals(J)\n        evals\n        stability_per = np.zeros(len(evals))\n        for i in range(0,len(evals)):\n          real_part = np.real(evals[i])\n          if real_part > 0:\n            un = 1\n            stability_per[i] =un\n          else:\n            un = 0\n            stability_per[i] = un\n        value = np.zeros(len(new_values[j]))\n        if stability_per.any()==1:\n          value = 1\n        else:\n          value = 0\n        stability.append(value)\n  return p_all, new_values, stability\n\n\n# In[59]:\n\n\n# def plot_stability(A, a):\n#     #p_values = np.arange(0, 0.2, 0.001)\n#     p_all, new_values, stability = stability_func(A,a)\n#     w = [[p_all[i]] * len(new_values[i]) for i in range(len(new_values))]\n#     index_unstable = np.where(np.array(stability)==1)\n\n#     x_to_plot = [item for sublist in w for item in sublist]\n#     y_to_plot = [item for sublist in new_values for item in sublist]\n#     x_array = np.array(x_to_plot)\n#     y_array = np.array(y_to_plot)\n#     x_array[index_unstable]\n#     plt.scatter(x_to_plot, y_to_plot)\n#     plt.scatter(x_array[index_unstable], y_array[index_unstable], marker = \"d\")\n#     plt.show()\n# # Define the interactive plot\n# interactive_plot = interactive(plot_stability, A = (0, 10.0), a=(50, 150))\n\n# # Display the interactive plot\n# output = interactive_plot.children[-1]\n# output.layout.height = '350px'\n# interactive_plot\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n\n# In[60]:\n\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Define the figure and axis objects\nfig = plt.figure(figsize=(15, 5))\nax = fig.add_subplot(122, projection='3d')\n\n# Calculate the limits for each dimension\nzmax = df_JR.y_2.max() + df_JR.y_2.std() * 1.5\nzmin = df_JR.y_2.min() - df_JR.y_2.std() * 1.5\nymax = df_JR.y_1.max() + df_JR.y_1.std() * 1.5\nymin = df_JR.y_1.min() - df_JR.y_1.std() * 1.5\nxmax = df_JR.y_0.max() + df_JR.y_0.std() * 1.5\nxmin = df_JR.y_0.min() - df_JR.y_0.std() * 1.5\n\n# Plot the trajectory as a line\nax.plot(df_JR.y_0, df_JR.y_1, df_JR.y_2)\n\n# Set the limits for each dimension\nax.set_xlim(xmin, xmax)\nax.set_ylim(ymin, ymax)\nax.set_zlim(zmin, zmax)\n\n\n# Show the plot\nplt.show()\n\n\n\n\n# In[62]:\n\n\n# fig, ax = plt.subplots(ncols=2, figsize=(12,3))\n\n# # V and W vs. time\n# df_VW.plot(ax=ax[0])\n\n# # V vs. W trajectory\n# ymax = df_VW.W.max() + df_VW.W.std()*1.5\n# ymin = df_VW.W.min() - df_VW.W.std()*1.5\n# xmax = df_VW.V.max() + df_VW.V.std()*1.5\n# xmin = df_VW.V.min() - df_VW.V.std()*1.5\n# df_VW.plot(x='V', y='W', legend=False,ax=ax[1],\n#            xlim=[xmin,xmax],ylim=[ymin,ymax],alpha=0.5);\n\n\n\n# In[ ]:\n\n\n\n\n\n# Bifurcation\n\n# In[63]:\n\n\n# df_JR = pd.DataFrame([y_0[1000:2000],y_1[1000:2000], y_2[1000:2000]],\n#                      index=['y_0', 'y_1', 'y_2'],\n#                      columns=time[1000:2000]).T\n\n\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection='3d')\n\n# Plot the 3D trajectory\nax.plot3D(df_JR.index, df_JR['y_0'], df_JR['y_1'], label='y_0')\nax.plot3D(df_JR.index, df_JR['y_0'], df_JR['y_2'], label='y_1')\nax.plot3D(df_JR.index, df_JR['y_1'], df_JR['y_2'], label='y_2')\n\n# Set the plot limits and labels\nax.set_xlim([df_JR.index .min(), df_JR.index .max()])\nax.set_ylim([df_JR['y_0'].min(),  df_JR['y_0'].max()])\nax.set_zlim([df_JR['y_2'].min(), df_JR['y_2'].max()])\nax.set_xlabel('Time')\nax.set_ylabel('y')\nax.set_zlabel('z')\n\n# Add a legend\nax.legend()\n\n# Show the plot\nplt.show()\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n\n# ### Network model of whole-brain anatomical connectivity\n\n# In[64]:\n\n\n# TVB stuff\nfrom tvb.simulator.lab import (models,connectivity,coupling,integrators,noise,simulator,\n                              surfaces,region_mapping,monitors,equations,patterns,plot_pattern)\n\n\n# In[65]:\n\n\nget_ipython().system('mkdir rois')\nparcel_dir = './rois/'\natlas_schaefer_2018 = datasets.fetch_atlas_schaefer_2018(n_rois=200,\n                                                         yeo_networks=7,\n                                                         resolution_mm=2,\n                                                         data_dir=parcel_dir)\n\n\n# In[66]:\n\n\n#Define where to slice the image\ncut_coords = (8, -4, 9)\n#Show a colorbar\ncolorbar=True\n#Color scheme to show when viewing image\ncmap='Paired'\n\n#Plot the parcellation schema referred to by atlas_schaefer_2018\nnplot.plot_roi(atlas_schaefer_2018['maps'], cut_coords=cut_coords, colorbar=colorbar, cmap=cmap, title='Schaefer et al. 2018')\n\n\n# In[67]:\n\n\nurl = 'https://raw.githubusercontent.com/ThomasYeoLab/CBIG/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/MNI/Centroid_coordinates/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv'\natlas = pd.read_csv(url)\nlabel = atlas['ROI Name']\n\nlabel_stripped = []\n\nfor xx in range(len(label)):\n    label_stripped.append(label[xx].replace('7Networks_',''))\n\n\ncoords = np.array([atlas['R'], atlas['A'], atlas['S']]).T\nconduction_velocity = 5 #in ms\n\ndistance = np.zeros((coords.shape[0], coords.shape[0]))\n\nfor roi1 in range(coords.shape[0]):\n  for roi2 in range(coords.shape[0]):\n    distance[roi1, roi2] = np.sqrt(np.sum((coords[roi1,:] - coords[roi2,:])**2, axis=0))\n    distance[roi1, roi2] = np.sqrt(np.sum((coords[roi1,:] - coords[roi2,:])**2, axis=0))\n\n\n\n\n# **Structural Connectivity**\n#\n# The structural connectivity (SC) scales the long-range connections between distant brain regions. Mathematically, together with the global scaling factor G, it is a factor of the long-range input onto a region.\n# In the simplest case, without time edelays, local connectivity and noise:\n# \\begin{equation}\n# \\dot{x}_i = N(x_{i}(t)) + G\\sum_1^n SC_{ij} x_j\n# \\end{equation}\n# Wherein $\\dot{x}_i$ is the derivative of the date variable, $N(x_{i}(t))$ is the nerual mass model function, $G$ is the global scaling factor, $SC_{ij}$ is the connections strength between regions $i$ and $j$ and $x_j$ is the output from region $j$.\n\n# In[70]:\n\n\ndef NormalizeData(data):\n         return (data - np.min(data)) / (np.max(data) - np.min(data))\n\n\nurl = \"https://raw.githubusercontent.com/GriffithsLab/PyTepFit/main/data/Schaefer2018_200Parcels_7Networks_count.csv\"\ncount = NormalizeData(np.array(pd.read_csv(url,  header=None, sep=' ')))\n\ndelays = distance/conduction_velocity\n\nfig, axes = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\nfig.suptitle('connectome matrices')\n\n# distance\nsns.heatmap(delays, cmap='viridis', ax=axes.flat[0], square=True)\naxes.flat[0].set_title('Conduction Delays ')\n#axes.flat[0].set_xticklabels(label_stripped, rotation=90);\n# axes.flat[0].set_yticklabels(label_stripped, rotation=0);\n\n# wieghts (normalized between 0 and 3)\nsns.heatmap(count, vmin=0.0, vmax=count.mean(), cmap='viridis', ax=axes.flat[1], square=True)\naxes.flat[1].set_title('Normalized count')\n#axes.flat[1].set_xticklabels(label_stripped, rotation=90)\n# axes.flat[1].set_yticklabels(label_stripped, rotation=0)\n\n\n# In[71]:\n\n\nconn = connectivity.Connectivity()\nconn.weights = count\nconn.region_labels = np.array(label_stripped)\nconn.delays = delays\nconn.centres = coords\nconn.tract_lengths = distance\n\n\nSchaefer_parcel = nl.image.load_img(atlas_schaefer_2018['maps']).get_fdata().flatten()\n\n\nareas=[]\nfor value in range(1,np.unique(Schaefer_parcel).shape[0]):\n    areas.append(np.where(Schaefer_parcel==value)[0].shape[0])\n\nareas= np.array(areas)\nconn.areas = areas\nconn.number_of_connections = np.count_nonzero(conn.weights)\n\nconn.cortical = np.broadcast_to(True, (conn.weights.shape[0]))\nconn.orientations = np.zeros((conn.centres.shape))\n\nconn.configure()\n\n\n# In[72]:\n\n\ndef simulate_resting_state(simlength=1000., tavg_per=1, conn=None, sigma=None, jrm_params=None, cpl_params=None, int_dt=0.5, speed=3.):\n    # Define the connectivity\n    if conn is None:\n        conn = connectivity.Connectivity.from_file()  # Assuming you have a connectivity file or use load_default=True\n        conn.speed = np.array([speed])\n        conn.configure()\n\n    # Define the model\n    if jrm_params is None:\n        jrm_params = dict(v0=np.array([6.]))\n    else:\n        jrm_params = {k: np.array([v]) for k, v in jrm_params.items()}\n    jrm = models.JansenRit(**jrm_params)\n    jrm.variables_of_interest = ('y0', 'y1', 'y2', 'y3', 'y4', 'y5')\n    jrm.stvar = np.array([0, 1, 2, 3, 4, 5])\n\n    # Set the noise\n    if sigma is None:\n        phi_n_scaling = (jrm.a * jrm.A * (jrm.p_max - jrm.p_min) * 0.5) ** 2 / 2.\n        sigma = np.zeros(6)\n        sigma[3] = phi_n_scaling * 1e-5  # Shrink noise by 1e-5\n\n    # Define the coupling\n    if cpl_params is None:\n        cpl_params = dict(a=np.array(0.00045))\n    else:\n        cpl_params = {k: np.array([v]) for k, v in cpl_params.items()}\n    cpl = coupling.SigmoidalJansenRit(**cpl_params)\n\n    # Set up the integration scheme\n    solver = integrators.HeunStochastic(dt=int_dt, noise=noise.Additive(nsig=sigma))\n\n    # Define initial conditions\n    init_conds = np.zeros([100, 6, conn.weights.shape[0], 1])  # All zeros; doesn't matter as we are using stochastic integration\n\n    # Define the monitor for temporal averaging\n    tavg_mon = monitors.TemporalAverage()\n    tavg_mon.period = tavg_per\n\n    # Create the simulator object\n    sim = simulator.Simulator(\n        model=jrm,\n        connectivity=conn,\n        coupling=cpl,\n        integrator=solver,\n        initial_conditions=init_conds,\n        simulation_length=simlength,\n        monitors=(tavg_mon,),\n    ).configure()\n\n    # Run the simulation and obtain the temporal average data\n    tavg_data = sim.run()\n\n    # Return the temporal average data\n    return tavg_data\n\n\n# In[73]:\n\n\nres = simulate_resting_state(simlength=5000, conn=conn,  sigma=None, jrm_params=None,\n                             cpl_params=None, int_dt=0.5, speed=3.)\n\n\n# In[74]:\n\n\ndf_cPN = pd.DataFrame(np.squeeze(res[0][1][:,0,:]),index=res[0][0])\ndf_cPN.index.names = ['t']\ndf_cPN.columns.names = ['region']\ndf_cPN.columns = [label_stripped]\n\ndf_cEIN = pd.DataFrame(np.squeeze(res[0][1][:,1,:]),index=res[0][0])\ndf_cEIN.index.names = ['t']\ndf_cEIN.columns.names = ['region']\ndf_cEIN.columns = [label_stripped]\n\ndf_cIIN = pd.DataFrame(np.squeeze(res[0][1][:,2,:]),index=res[0][0])\ndf_cIIN.index.names = ['t']\ndf_cIIN.columns.names = ['region']\ndf_cIIN.columns = [label_stripped]\n\ndf_vPN = pd.DataFrame(np.squeeze(res[0][1][:,3,:]),index=res[0][0])\ndf_vPN.index.names = ['t']\ndf_vPN.columns.names = ['region']\ndf_vPN.columns = [label_stripped]\n\ndf_vEIN = pd.DataFrame(np.squeeze(res[0][1][:,4,:]),index=res[0][0])\ndf_vEIN.index.names = ['t']\ndf_vEIN.columns.names = ['region']\ndf_vEIN.columns = [label_stripped]\n\ndf_vIIN = pd.DataFrame(np.squeeze(res[0][1][:,5,:]),index=res[0][0])\ndf_vIIN.index.names = ['t']\ndf_vIIN.columns.names = ['region']\ndf_vIIN.columns = [label_stripped]\n\n\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n\ndf = df_cEIN - df_cIIN\n\ndf.index = np.round(df.index,1)\n\nfig, ax = plt.subplots(nrows=2, figsize=(12,6))\n\nfig = ax[0].plot(df)\nfig = ax[1].plot(df[1000:2000])\n\n\n# In[ ]:\n\n\n\n\n\n# **Leadfield**\n#\n# The leadfiled matrix is used to project local field potentials from region level (inside the brain) to the scalp surface for the calculation of EEG signals.\n#\n# $$M = GX + E$$\n#\n# where $M \\in \\mathbb{R}^{C \\times T}$ is the sensor data, $G \\in \\mathbb{R}^{C \\times S}$ is the lead-field (or gain) matrix, $X \\in \\mathbb{R}^{S \\times T}$ is the source time course (stc) and $E \\in \\mathbb{R}^{C \\times T}$ is additive Gaussian noise with zero mean and identity covariance\n#\n#\n# Here, we use pre-calculated matrix.\n\n# In[75]:\n\n\nleadfield = np.load('./data/leadfield', allow_pickle=True)\n\nepoched = mne.read_epochs('./data/all_avg.mat_avg_high_epoched')\n\nfor trial in range(epoched._data.shape[0]):\n  epoched._data[trial,:,:] = np.array(leadfield @ df[2000:4000].T)\n\nevoked = epoched.average()\n\n\n# In[76]:\n\n\n_, ax = plt.subplots()\nspectrum = epoched.compute_psd(fmin=2.0, fmax=40.0, tmax=3.0, n_jobs=None)\n# average across epochs first\nmean_spectrum = spectrum.average()\npsds, freqs = mean_spectrum.get_data(return_freqs=True)\n# then convert to dB and take mean & standard deviation across channels\npsds = 10 * np.log10(psds)\npsds_mean = psds.mean(axis=0)\npsds_std = psds.std(axis=0)\n\nax.plot(freqs, psds_mean, color=\"k\")\nax.fill_between(\n    freqs,\n    psds_mean - psds_std,\n    psds_mean + psds_std,\n    color=\"k\",\n    alpha=0.5,\n    edgecolor=\"none\",\n)\nax.set(\n    title=\"Multitaper PSD (eeg)\",\n    xlabel=\"Frequency (Hz)\",\n    ylabel=\"Power Spectral Density (dB)\",\n)\n\n\n# In[77]:\n\n\nfreqs = np.logspace(*np.log10([6, 35]), num=8)\nn_cycles = freqs / 2.0  # different number of cycle per frequency\npower, itc = mne.time_frequency.tfr_morlet(\n    epoched,\n    freqs=freqs,\n    n_cycles=n_cycles,\n    use_fft=True,\n    return_itc=True,\n    decim=3,\n    n_jobs=None,\n)\n\n\npower.plot_topo(baseline=(-0.5, 0), mode=\"logratio\", title=\"Average power\")\npower.plot([epoched.ch_names.index('O1')],\n           baseline=None, mode=\"logratio\",\n           title=power.ch_names[epoched.ch_names.index('O1')])\n\nfig, axes = plt.subplots(1, 2, figsize=(7, 4), constrained_layout=True)\ntopomap_kw = dict(\n    ch_type=\"eeg\", tmin=epoched.times[0], tmax=epoched.times[-1], baseline=None, mode=\"logratio\", show=False\n)\nplot_dict = dict(Alpha=dict(fmin=8, fmax=12), Beta=dict(fmin=13, fmax=25))\nfor ax, (title, fmin_fmax) in zip(axes, plot_dict.items()):\n    power.plot_topomap(**fmin_fmax, axes=ax, **topomap_kw)\n    ax.set_title(title)\n\n\n# In[ ]:\n\n\n\n\n\n# ### Here we will add an external perturbation to show how we can simulated evoked activity\n\n# In[78]:\n\n\ndef run_sim(g2do_params,conn=None,\n            sim_len = 2e3,dt = 0.5,\n            tau = 2,lca=0.01,\n            tavg_per = 1.0,\n            stim_eqn_onset =None,\n            stim_eqn_T = None,\n            stim_eqn_tau = None,\n            stim_weight = None,\n            leadfield = None):\n\n    if conn == None:\n        conn = connectivity.Connectivity(load_default=True)\n\n    model = models.Generic2dOscillator(**g2do_params)\n    cpl=coupling.Linear(a=np.array(lca))\n    solver=integrators.HeunDeterministic(dt=0.1)\n    mons=(monitors.TemporalAverage(period=tavg_per),)\n\n    eqn_t = equations.PulseTrain()\n    eqn_t.parameters['onset'] = stim_eqn_onset\n    eqn_t.parameters['T'] = stim_eqn_T\n    eqn_t.parameters['tau'] = stim_eqn_tau\n\n    weighting = stim_weight\n\n    stimulus = patterns.StimuliRegion(temporal=eqn_t,\n                                    connectivity=conn,\n                                    weight=weighting)\n    stimulus.configure_space()\n    stimulus.configure_time(np.arange(0., 3e3, 2**-4))\n\n    sim = simulator.Simulator(model = model,connectivity=conn,coupling=cpl,\n                            integrator=solver,\n                            monitors=mons,\n                            stimulus=stimulus)\n    sim.configure()\n\n    (tavg_time, tavg_data), = sim.run(simulation_length=sim_len)\n\n\n    df_tavg = pd.DataFrame(np.squeeze(tavg_data),index=tavg_time)\n    df_tavg.index.names = ['t']\n    df_tavg.columns.names= ['node']\n    df_tavg.columns = conn.region_labels\n\n    EEG = leadfield.dot(np.array(df_tavg).T).T # EEG shape [n_samples x n_eeg_channels]\n\n    # reference is mean signal, tranposing because trailing dimension of arrays must agree\n    EEG = (EEG.T - EEG.mean(axis=1).T).T\n\n    # analyze signal, get baseline and frequency\n    eeg_baseline = EEG.mean(axis=0)\n    EEG = EEG - EEG.mean(axis=0)  # center EEG\n\n    plot_pattern(stimulus)\n\n    return df_tavg, EEG\n\n\n# In[79]:\n\n\ngamma_sp = 1.21\nepsilon_sp =  12.3083\n\n# is this the correct?\n# - units in Spiegler are S^-1.\n# - default value for g2do d is 0.02\n# - so this gives 0.07674\neta_sp = np.array([(1/1000.) * 76.74])   #eta_sp = 76.74 # 1. # 76.74 ##1. # 76.74 # 1.\n\n#eta_sp = np.array([0.2])\n\nsp_g2do_params = dict(d = eta_sp,\n                      tau = np.array(1.),\n                      f = np.array(1.),\n                      e = np.array(3.0),\n                      g = np.array(-gamma_sp),\n                      alpha = np.array(2.),\n                      gamma = np.array(1.),\n                      c = np.array(0.),\n                      b= np.array(-epsilon_sp), # should not be negative? LOOKS LIKE IT AL COMES DOWN TO THIS PARAM\n                      beta = np.array(1.0),\n                      a = np.array(0.))\n\n\n# In[80]:\n\n\nSomMot = [index for index, word in enumerate(list(conn.region_labels)) if 'SomMot' in word]\n\nstim_weights = np.zeros((conn.region_labels.shape[0]))\nstim_weights[SomMot[:16]] = 0.5 #inject stimulus to left hemi\n\n\n# In[81]:\n\n\nnode2use = np.where(stim_weights!=0)[0]\n\nstim_weighting = np.zeros(conn.region_labels.shape[0])\n#stim_weighting[node2use] = 0.1\n\n# configure stimulus spatial pattern\nstim_weight = stim_weights[np.where(stim_weights!=0)[0]]\nstim_weighting[np.where(stim_weights!=0)[0]] = stim_weight\n\n\n\ndf_tavg_sp1, EEG = run_sim(sp_g2do_params,conn=conn, lca=0.5,sim_len=5000, \\\n                      stim_eqn_onset =1250, stim_eqn_T = 1500.0,\n                      stim_eqn_tau = 50.0, \\\n                      stim_weight=stim_weighting, leadfield=leadfield)\n\n\n# In[82]:\n\n\nfig, ax = plt.subplots(nrows=2, figsize=(12,6))\n\nfig = ax[0].plot(np.array(df_tavg_sp1))\nfig = ax[1].plot(np.array(df_tavg_sp1)[1000:1500])\nax[1].set_ylim([-0.05, 0.05])\n\n\n# In[83]:\n\n\nepoched = mne.read_epochs('./data/all_avg.mat_avg_high_epoched')\n\nfor trial in range(epoched._data.shape[0]):\n  epoched._data[trial,:,:] = EEG[250:2250,:].T\n\nevoked = epoched.average()\n\n\n# In[84]:\n\n\nts_args = dict(xlim=[-0.025,0.1])\nch, peak_locs1 = evoked.get_peak(ch_type='eeg', tmin=-0.005, tmax=0.004)\nch, peak_locs2 = evoked.get_peak(ch_type='eeg', tmin=0.008, tmax=0.1)\nch, peak_locs3 = evoked.get_peak(ch_type='eeg', tmin=0.030, tmax=0.1)\ntimes = [peak_locs1, peak_locs2, peak_locs3]\n\nevoked.plot_joint(ts_args=ts_args, times=times, title='Propagation pattern');\n\n\n# ### Conclusions\n\n#\n\n# ### References\n\n#\n# > Jansen, B.H. and Rit, V.G. (1995) **Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns.** *Biological cybernetics*, 73(4), pp.357-366.\n#\n# > Da Silva, F.L., Hoeks, A., Smits, H. and Zetterberg, L.H. (1974). **Model of brain rhythmic activity.** *Kybernetik*, 15(1), pp.27-37.\n#\n# > David, O. and Friston, K.J. (2003) **A neural mass model for MEG/EEG: coupling and neuronal dynamics.** *NeuroImage*, 20(3), pp.1743-1755.\n#\n# > Spiegler, A., Kn\u00f6sche, T.R., Schwab, K., Haueisen, J. and Atay, F.M. (2011). **Modeling brain resonance phenomena using a neural mass model.** *PLoS Comput Biol*, 7(12), p.e1002298.\n#\n# > Momi, D., Wang, Z., Griffiths, J.D. (2023). **TMS-Evoked Responses Are Driven by Recurrent Large-Scale Network Dynamics\n# .** *eLife*, 111, pp.385-430.\n#\n\n# #### For any question feel free to reach out:\n\n# ***Dr. Davide Momi***<br/>\n# ------------<br/>\n# Post-Doctoral Research Fellow<br/>\n# Whole Brain Modelling Group<br/>\n# Krembil Centre for Neuroinformatics - CAMH<br/>\n# 250 College St., Toronto, ON M5T 1R8<br/>\n# <br/>\n# website: https://davi1990.github.io/<br/>\n# Twitter: @DaveMomi<br/>\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}